# =============================================================================
# CONSOLIDATED ENVIRONMENT CONFIGURATION - EXAMPLE
# =============================================================================
# Copy this file to .env and fill in your actual values

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose one: "openai" or "azure"
LLM_PROVIDER=azure

# =============================================================================
# OPENAI CONFIGURATION
# =============================================================================
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# AZURE OPENAI CONFIGURATION
# =============================================================================
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5
AZURE_OPENAI_API_VERSION=2025-04-01-preview
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-3-large
EMBEDDING_MODEL_DIM=3072

# =============================================================================
# ANTHROPIC CONFIGURATION (Optional)
# =============================================================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =============================================================================
# LANGSMITH CONFIGURATION
# =============================================================================
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=salla-ops-system
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# =============================================================================
# BACKEND API CONFIGURATION
# =============================================================================
# Note: Use localhost for browser-side requests (NEXT_PUBLIC_ vars are exposed to browser)
# The browser cannot resolve Docker service names like "backend"
NEXT_PUBLIC_API_URL=http://localhost:8000

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
ENVIRONMENT=development
LOG_LEVEL=INFO
PORT=3000
