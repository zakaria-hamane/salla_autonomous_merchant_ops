# 5. Reasoning Audit & Debugging Analysis

## 1. Hallucination Fix Example

### The "Phantom Competitor" Incident

During development of the `pricing_agent`, we observed a specific hallucination where the LLM would invent competitor pricing data to justify a price decrease, even when no competitor data was provided in the `pricing_context`.

**Scenario:**
- **Input:** Product "Espresso Maker" ($120). No competitor data in CSV.
- **Agent Reasoning:** "Competitor selling at $85.00. Proposing drop to $90.00."
- **Result:** Unjustified revenue loss.

### Detection & Fix

We implemented a **Validator Node** downstream of the pricing agent. This node does not use an LLM; it uses deterministic Python logic (Regex) to parse the `signals_used` array generated by the agent and cross-reference it with the raw source of truth.

**Implementation Logic (`nodes.py` -> `validator_node`):**

```python
# Extract claimed price from agent rationale
match = re.search(r"competitor_price:\s*\$?([\d\.]+)", signal)
if match:
    claimed_price = float(match.group(1))
    
    # Compare against Ground Truth (pricing_context)
    actual_price = context_map.get(pid)
    
    if actual_price is None:
        # FACT: Agent cited a price, but data is null.
        flag = {"type": "HALLUCINATION", "message": "Cited competitor price that doesn't exist."}
```

**Evidence (Trace Summary):**
- **Trace ID:** `run-sim-hallucination-001` (Generated via `tests/generate_trace_evidence.py`)
- **Input:** `signals_used=["competitor_price: $85.00"]`
- **Context:** `pricing_context=[]`
- **Output Action:** `status="BLOCKED"`, `note="Blocked: Agent hallucinated data source."`

### How to Reproduce

Run the evidence generation script:

```bash
cd backend
python tests/generate_trace_evidence.py
```

This will demonstrate the complete detection pipeline in action.

---

## 2. Production Safeguards

### A. Schema Violation Detection

To ensure downstream agents (like Pricing) receive valid data structure, we employ a "Schema Gate" pattern.

**Strict Pydantic Definitions:** The `catalog_agent` uses `JsonOutputParser` with a strictly typed Pydantic model (`CatalogAnalysis`).

**Retry Loop:** If the LLM generates invalid JSON (missing keys, wrong types), the parser raises an exception.

**Gate Logic (`graph.py`):**
- The `check_schema_gate` function inspects `state["schema_validation_passed"]`.
- If `False`: It increments `retry_count`. If `retry_count < 2`, it loops back to `catalog_agent` for a regeneration attempt.
- If Failed Twice: It marks the data as "invalid" and the Conflict Resolver creates a fallback plan.

**Example:**
```python
def check_schema_gate(state: Dict[str, Any]) -> str:
    if not state.get("schema_validation_passed", False):
        if state.get("retry_count", 0) < 2:
            return "catalog_agent"  # Retry
        else:
            return "conflict_resolver"  # Fallback
    return "support_agent"
```

### B. Contradictory Output Detection

We verify logical consistency between the Support Agent (Sentiment) and Pricing Agent (Decisions).

**Logic:** A price increase is contradictory if market sentiment is strongly negative.

**Implementation:**
- `validator_node` reads `state["sentiment_score"]`.
- If `sentiment < -0.3` AND `proposal["status"] == "INCREASE"`:
  - A `CONTRADICTION` flag is raised.

**Result:** The `conflict_resolver_node` automatically blocks the increase, ensuring the AI doesn't anger customers during a PR crisis.

**Code Example:**
```python
if proposal.get("status") == "INCREASE" and sentiment < -0.3:
    flag = {
        "product_id": pid,
        "type": "CONTRADICTION",
        "severity": "MEDIUM",
        "message": f"Proposed price increase contradicts negative market sentiment ({sentiment:.2f})."
    }
    validation_flags.append(flag)
```

---

## 3. Reliability Metrics

We calculate the following metrics at the end of every run (in `conflict_resolver_node`) to monitor agent health.

| Metric | Definition | Target |
|--------|-----------|--------|
| **Pricing Pass Rate** | `(Approved Proposals / Total Proposals) * 100` | > 80% |
| **Automated Block Rate** | `(Blocked Proposals / Total Proposals) * 100` | < 10% |
| **Hallucination Rate** | `(Hallucination Flags / Total Proposals) * 100` | 0% |
| **Sentiment Score** | Normalized score from -1.0 (Hostile) to 1.0 (Positive). Derived from aggregating support classifications. | > 0.0 |

### Calculation Example (from `nodes.py`):

```python
metrics = {
    "pricing_pass_rate": round((approved_ops / total_ops * 100), 1),
    "automated_block_rate": round((blocked_ops / total_ops * 100), 1),
    "hallucination_rate": round((hallucination_count / total_ops * 100), 1),
    "sentiment_score": sentiment
}
```

These metrics are injected into the `final_report` JSON and visible on the dashboard.

### Metric Interpretation

- **High Pass Rate (>80%):** System is operating efficiently with minimal false positives.
- **Low Block Rate (<10%):** Agents are generating high-quality proposals that pass validation.
- **Zero Hallucination Rate:** Critical safety requirement - any non-zero value triggers investigation.
- **Positive Sentiment:** Market conditions are favorable for automated operations.

---

## 4. Verification Checklist

✅ **Code:** `conflict_resolver_node` now calculates and logs reliability metrics.

✅ **Evidence:** `generate_trace_evidence.py` can be run to prove hallucination detection works.

✅ **Report:** This document (`REASONING_AUDIT.md`) clearly defines the methodology, safeguards, and metrics.

---

## 5. Future Improvements

1. **LangSmith Integration:** Connect trace generation to LangSmith for persistent trace storage and analysis.
2. **Metric Dashboards:** Visualize metrics over time to identify degradation patterns.
3. **Automated Alerts:** Trigger notifications when hallucination rate exceeds 0% or pass rate drops below 80%.
4. **A/B Testing:** Compare different prompt strategies using these metrics as success criteria.

---

**Document Version:** 1.0  
**Last Updated:** February 7, 2026  
**Author:** Multi-Agent System Development Team
